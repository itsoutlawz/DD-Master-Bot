name: DamaDam Master Bot Scraper

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Chrome
        uses: browser-actions/setup-chrome@latest
      
      - name: Run scraper
        env:
          DAMADAM_USERNAME: ${{ secrets.DAMADAM_USERNAME }}
          DAMADAM_PASSWORD: ${{ secrets.DAMADAM_PASSWORD }}
          DAMADAM_USERNAME_2: ${{ secrets.DAMADAM_USERNAME_2 }}
          DAMADAM_PASSWORD_2: ${{ secrets.DAMADAM_PASSWORD_2 }}
          GOOGLE_SHEET_URL: ${{ secrets.GOOGLE_SHEET_URL }}
          GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
          MAX_PROFILES_PER_RUN: 100
          BATCH_SIZE: 10
          MIN_DELAY: 0.5
          MAX_DELAY: 0.7
          PAGE_LOAD_TIMEOUT: 30
          SHEET_WRITE_DELAY: 1.0
        run: python Scraper.py
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraper-logs
          path: |
            *.log
            damadam_cookies.pkl
          retention-days: 7
