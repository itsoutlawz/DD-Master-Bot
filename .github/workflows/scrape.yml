name: DamaDam Scraper

on:
  schedule:
    # Run every 8 hours: 00:00, 08:00, 16:00 UTC
    - cron: '0 */8 * * *'
  
  workflow_dispatch:
    inputs:
      mode:
        description: 'Run Mode'
        required: true
        type: choice
        options:
          - online
          - sheet
        default: 'online'
      
      profile_limit:
        description: 'Profile Limit (0 = no limit)'
        required: false
        type: number
        default: 0
      
      repeat_mode:
        description: 'Enable Repeat Mode (5 min delay)'
        required: false
        type: boolean
        default: false

# Cancel previous runs when new one starts
concurrency:
  group: scraper-${{ github.ref }}
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 480  # 8 hours max
    
    steps:
      - name: ðŸ”„ Cancel Previous Runs
        uses: styfle/cancel-workflow-action@0.11.0
        with:
          access_token: ${{ github.token }}
      
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v3
      
      - name: ðŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: ðŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: ðŸŒ Setup Chrome
        uses: browser-actions/setup-chrome@latest
      
      - name: ðŸ”§ Setup ChromeDriver
        uses: nanasess/setup-chromedriver@master
      
      - name: ðŸ“‹ Create .env File
        run: |
          echo "GOOGLE_CREDENTIALS=${{ secrets.GOOGLE_CREDENTIALS }}" >> .env
          echo "SHEET_URL=${{ secrets.SHEET_URL }}" >> .env
      
      - name: ðŸš€ Run Scraper (Scheduled - Auto Mode)
        if: github.event_name == 'schedule'
        run: |
          python Scraper.py --mode online --repeat
      
      - name: ðŸš€ Run Scraper (Manual)
        if: github.event_name == 'workflow_dispatch'
        run: |
          MODE="${{ github.event.inputs.mode }}"
          LIMIT="${{ github.event.inputs.profile_limit }}"
          REPEAT="${{ github.event.inputs.repeat_mode }}"
          
          CMD="python Scraper.py --mode $MODE"
          
          if [ "$LIMIT" != "0" ]; then
            CMD="$CMD --limit $LIMIT"
          fi
          
          if [ "$REPEAT" == "true" ]; then
            CMD="$CMD --repeat"
          fi
          
          echo "Running: $CMD"
          $CMD
      
      - name: ðŸ“Š Summary
        if: always()
        run: |
          echo "## ðŸ“Š Scraper Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: ${{ github.event.inputs.mode || 'online (scheduled)' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Profile Limit**: ${{ github.event.inputs.profile_limit || 'No limit' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Repeat Mode**: ${{ github.event.inputs.repeat_mode || 'true (scheduled)' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Time**: $(date)" >> $GITHUB_STEP_SUMMARY
